{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECOND POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will to improve our results by building different CNN with different characteristics. We perform data augmentation in order to have more data to train my network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from dataSetUtility.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import keras as ks\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation, BatchNormalization, AveragePooling2D, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import import_ipynb\n",
    "import dataSetUtility as dsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Images, resharpe it and split in train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class number:  15\n",
      "Class names:  ['Bedroom', 'Coast', 'Forest', 'Highway', 'Industrial', 'InsideCity', 'Kitchen', 'LivingRoom', 'Mountain', 'Office', 'OpenCountry', 'Store', 'Street', 'Suburb', 'TallBuilding']\n",
      "len Train Set:  1275\n",
      "len Validation Set:  225\n",
      "len Test Set:  2985\n"
     ]
    }
   ],
   "source": [
    "#path to the directories\n",
    "pathTrain=r'C:\\Users\\adria\\Desktop\\CVPR\\ImageSet\\train'\n",
    "pathTest=r'C:\\Users\\adria\\Desktop\\CVPR\\ImageSet\\test'\n",
    "\n",
    "labels = [os.path.basename(i) for i in glob.glob(pathTrain + '/*', recursive=True)]\n",
    "numberOfClasses = len(labels)\n",
    "xTrainRaw, yTrainRaw = dsu.loadImages(pathTrain, labels)\n",
    "xTest, yTest = dsu.loadImages(pathTest, labels)\n",
    "xTrainRaw = dsu.reshape(xTrainRaw, 64,64,1)\n",
    "xTest = dsu.reshape(xTest,64,64,1)\n",
    "yTrainCategorical = to_categorical(yTrainRaw)\n",
    "yTestCategorical = to_categorical(yTest)\n",
    "\n",
    "xTrain, xValidation, yTrain, yValidation = train_test_split(xTrainRaw, yTrainCategorical, train_size=0.85, random_state=275)\n",
    "\n",
    "print(\"Class number: \", numberOfClasses)\n",
    "print(\"Class names: \", labels)\n",
    "print('len Train Set: ',len(xTrain))\n",
    "print('len Validation Set: ',len(xValidation))\n",
    "print('len Test Set: ',len(xTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the results we try to increase the number of data following a transformation from left to right."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
